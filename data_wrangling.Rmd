---
title: "data_wrangling"
author: "stat group"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r libraries & env variables, include=FALSE, echo=FALSE}
options(scipen=999); `%notin%` <- Negate(`%in%`)
lib_list <- c('dplyr','ipumsr','ggplot2','dtplyr',
              'stringr','tidyr','rvest','chatgpt',
              'xml2','purrr','tibble','yahoofinancer','YRmisc',
              'caret','ModelMetrics','yardstick','car')
lapply(lib_list, library, character.only=TRUE)
```

```{r parse_generalInfo}
#function to parse each worksheet and return a data frame
parse_generalInfo <- function(ws_ns, ws_node, index){
  ws_name <- xml_attr(ws_node, "Name", ws_ns)
  rows <- xml_find_all(ws_node, ".//ss:Row", ws_ns)
  #skip the first 6 rows
  rows <- rows[-(1:6)]
  #extract values per row
  row_data <- map(rows, function(row){
    cells <- xml_find_all(row, ".//ss:Cell", ws_ns)
    values <- map_chr(cells, ~ xml_text(xml_find_first(.x, ".//ss:Data", ws_ns)))
    return(values)})
  #skip empty worksheets
  if(length(row_data) == 0) return(tibble())  
  #pad and bind
  padded_data <- lapply(row_data, `length<-`, max(lengths(row_data)))
  parsed_df <- as.data.frame(do.call(rbind, padded_data), stringsAsFactors = FALSE) %>%
    mutate_all(~if_else(. == 'NA', NA, .)) %>%
    mutate(across(everything(), as.character))
  #coerce V2 to numeric
  v2_numeric <- suppressWarnings(as.numeric(parsed_df$V2))
  #find row indices where V2 is 1 and 51
  starts_raw <- which(v2_numeric == 1)
  ends <- which(v2_numeric == 51)
  #adjust start indices to be 4 rows earlier
  starts <- pmax(starts_raw - 4, 1)  # Ensure we don't go below row 1
  #build valid (non-overlapping) start:end ranges
  ranges <- list()
  used_ends <- c()
  for (i in seq_along(starts)){
    start <- starts[i]
    end_candidates <- ends[ends > starts_raw[i]]  # Ensure end is after raw "1"
    if (length(end_candidates) > 0){
      end <- end_candidates[1]
      if (!(end %in% used_ends)){
        ranges <- append(ranges, list(start:end))
        used_ends <- c(used_ends, end)}}}
  #flatten ranges into a vector of unique row indices to shift
  rows_to_shift <- unique(unlist(ranges))
  #shift V2–V16 left into V1–V15, set V16 to NA
  for (i in 1:15){parsed_df[rows_to_shift, paste0("V", i)] <- parsed_df[rows_to_shift, paste0("V", i + 1)]}
  parsed_df[rows_to_shift, "V16"] <- NA
  #data clean-up & manipulation
  parsed_df <- parsed_df %>%
    mutate(V8 = case_when(V7 %in% c(1996:2024) ~ V7,
                          .default = NA)) %>%
    #assign annual indicator
    fill(V8,.direction='down') %>%
    #create pivot version...based on annual values
    pivot_wider(id_cols = c(V1,V2),
                names_from = V8,
                values_from = V7,
                values_fn = list) %>%
    #collect relevant rows
    slice(2:110) %>%
    add_column(col_names=c('na1','gross_liab_prem','gross_prop_prem','gross_comined_prop_liab_prem','gross_other_lines_prem',
                           'gross_nonprop_reinsurance_prem','total_gross_prem','na2','net_liab_prem',
                           'net_prop_prem','net_comined_prop_liab_prem','net_other_lines_prem','net_nonprop_reinsurance_prem',
                           'total_net_prem','na3','net_underwriting_gain','net_investment_gain','total_other_income',
                           'dividends_to_policyholders','taxes_incurred','net_income','na4','total_assets','na5','prem_incourse','prem_deferred','prem_accured',
                           'total_liabilities','losses','loss_adjustment_expenses','unearned_prem','capital_paid_up','policyholders_surplus','na6','net_cash_from_operations','na7',
                           'total_adjusted_capital','control_level_capital','na8','na9','na10','bonds','stocks','real_estate_mortgage_loans','real_estate',
                           'cash_short-term_investment','contract_loans','derivatives','other_invested_assets','receivable_securities',
                           'securities_lending_reinvested_collateral_assets','agg_write-ins','cash_invested_assets','na11',
                           'affiliated_bonds','affiliated_preferred_stocks','affiliated_common_stocks','na12','affiliated_short-term_investments',
                           'affiliated_real_estate_mortgage_loans','other_affiliated','total_affiliated','total_in-parent_investment','na13',
                           'pct_affiliated_surplus','na14','net_unrealized_capital','divdends_to_stockholders',
                           'change_in-surplus_policyholders','na15','gross_liab_losses','gross_prop_losses','gross_comined_prop_liab_losses',
                           'na30','gross_other_lines_losses','gross_nonprop_reinsurance_losses','total_losses','na16',
                           'net_liab_losses','net_prop_losses','net_comined_prop_liab_losses','net_other_lines_losses',
                           'net_nonprop_reinsurance_losses','total_net_losses','na17','na18','earned_prem_percentage','incurred_losses',
                           'incurred_loss_expenses','other_incurred_underwriting_expenses','nwg',
                           'na19','na20','other_underwriting_expenses_to_net_prem','na21','imported_loss_ratio','na22','net_prem_to_policyholder_surplus','na23','na24',
                           '1yr_loss_development','na25','1yr_dev_loss_to_policyholders_surplus','na26','na27','2yr_loss_development',
                           'na28','na29','2yr_dev_loss_to_policyholders_surplus'),
               .before=2,.name_repair = 'minimal') %>%
    #collect relevant columns
    select(-c(V1,V2)) %>%
    #transpose data frame
    t() %>%
    as.data.frame() %>%
    #extract annual indicator from index
    rownames_to_column(var='index') %>%
    #convert data types from list...created by pivot operation
    mutate(across(where(is.list), ~ map_chr(.x, ~ paste(.x, collapse = ", "))))
  #assign column names
  colnames(parsed_df) <- parsed_df[1,]
  colnames(parsed_df)[1] <- 'Year'
  parsed_df <- parsed_df[-1,]
  #return final data frame
  return(parsed_df)
}
```

```{r parse_earnedPrem}
#function to parse each worksheet and return a data frame
parse_earnedPrem <- function(ws_ns, ws_node, index){
  ws_name <- xml_attr(ws_node, "Name", ws_ns)
  rows <- xml_find_all(ws_node, ".//ss:Row", ws_ns)
  #skip the first 6 rows
  #rows <- rows[-(1:6)]
  #extract values per row
  row_data <- map(rows, function(row){
    cells <- xml_find_all(row, ".//ss:Cell", ws_ns)
    values <- map_chr(cells, ~ xml_text(xml_find_first(.x, ".//ss:Data", ws_ns)))
    return(values)})
  #skip empty worksheets
  if(length(row_data) == 0) return(tibble())  
  #pad and bind
  padded_data <- lapply(row_data, `length<-`, max(lengths(row_data)))
  parsed_df <- as.data.frame(do.call(rbind, padded_data), stringsAsFactors = FALSE) %>%
    mutate_all(~if_else(. == 'NA', NA, .)) %>%
    mutate(across(everything(), as.character)) 
  title_str <- parsed_df[1,'V2']
  parsed_df <- parsed_df %>%
    slice(-c(1:7)) %>%
    select(V2,V3,V8,V9,V10,V11) %>%
    rename(lob_index=V2,lob=V3,net_written_prem=V8,prior_unearned_prem=V9,unearned_prem=V10,earned_prem=V11) %>%
    mutate(suppressWarnings(round(as.numeric(lob_index), 1)),
           across(c(net_written_prem,prior_unearned_prem,unearned_prem,earned_prem),~ suppressWarnings(as.numeric(.x))),
           year=as.integer(sub('.*December 31, (.*?) OF.*','\\1',title_str))) %>%
    filter(lob=='TOTALS') %>%
    select(year,earned_prem)
  parsed_df <- parsed_df %>%
    mutate(year=year-row_number()+1)
  return(parsed_df)
}
```

```{r parse_paidExpenses}
#function to parse each worksheet and return a data frame
parse_paidExpenses <- function(ws_ns, ws_node, index){
  ws_name <- xml_attr(ws_node, "Name", ws_ns)
  rows <- xml_find_all(ws_node, ".//ss:Row", ws_ns)
  #skip the first 6 rows
  #rows <- rows[-(1:6)]
  #extract values per row
  row_data <- map(rows, function(row){
    cells <- xml_find_all(row, ".//ss:Cell", ws_ns)
    values <- map_chr(cells, ~ xml_text(xml_find_first(.x, ".//ss:Data", ws_ns)))
    return(values)})
  #skip empty worksheets
  if(length(row_data) == 0) return(tibble())  
  #pad and bind
  padded_data <- lapply(row_data, `length<-`, max(lengths(row_data)))
  parsed_df <- as.data.frame(do.call(rbind, padded_data), stringsAsFactors = FALSE) %>%
    mutate_all(~if_else(. == 'NA', NA, .)) %>%
    mutate(across(everything(), as.character)) 
  title_str <- parsed_df[1,'V1']
  parsed_df <- parsed_df %>%
    slice(-c(1:6)) %>%
    select(V2,V3,V7,V8,V9,V11) %>%
    rename(label=V2,description=V3,lae=V7,underwriting_exp=V8,investment_exp=V9,total_exp=V11) %>%
    mutate(across(c(lae,underwriting_exp,investment_exp,total_exp),~ suppressWarnings(as.numeric(.x))),
           year=as.integer(sub('.*December 31, (.*?) OF.*','\\1',title_str))) %>%
    filter(label=='TOTAL EXPENSES PAID (Lines 25 - 26 + 27 - 28 + 29)') %>%
    select(year,lae,underwriting_exp,investment_exp,total_exp)%>%
    mutate(year=year-row_number()+1)
  return(parsed_df)
}
```

```{r parse_stockPrice}
#get historical market data
parse_stockPrice <- function(tick_df){
  tickers_df <- data.frame()
  for(tick in c(1:nrow(tick_df))){
    #initialize ticker
    temp_tick <- Ticker$new(tick_df[tick,'ticker'])
    #import historic data
    temp_price_df <- temp_tick$get_history(start = '1996-01-01', end = '2024-12-31', interval = '1d')[,c(1,7)]
    #aggregate information annually
    temp_price_df <- temp_price_df %>%
      group_by(Year = lubridate::year(date)) %>%
      mutate(adj_close = map_dbl(adj_close, ~ pluck(.x, 1, .default = NA_real_))) %>%
      summarize(across(adj_close, ~last(.))) %>%
      mutate(Company = tick_df[tick,'name'])
    #add ticker information to output data frame
    tickers_df <- rbind(tickers_df,temp_price_df)
  }
  #collect stock price information
  tickers_df <- tickers_df %>%
    #assign proper column formats
    mutate(stock_price = map_dbl(adj_close, ~ if(length(.x) > 0){.x[[1]]}else{NA_real_}),
           Year = as.character(Year)) %>%
    #drop adj_close column
    select(-adj_close)
  return(tickers_df)
}
```

```{r data_import}
#function to perform all data import operations
data_import<- function(input.df,input.indicators){
  #initialize output data frame
  orgs_df <- data.frame()
  #collect information from financial statements
  for(org in c(1:nrow(input.df))){
    #import .xml file
    temp_general_doc <- read_xml(paste0("../../research/fin_statements/general/",input.df[org,'name'],".xml"))
    temp_ep_doc <- read_xml(paste0("../../research/fin_statements/earned_prem/",input.df[org,'name'],".xml"))
    temp_paidExp_doc <- read_xml(paste0("../../research/fin_statements/paid_expenses/",input.df[org,'name'],".xml"))
    #initialize node information from file
    temp_general_ns <- xml_ns(temp_general_doc)
    temp_ep_ns <- xml_ns(temp_ep_doc)
    temp_paidExp_ns <- xml_ns(temp_paidExp_doc)
    #extract information about all 'Worksheet' nodes...annual information
    temp_general_wks <- xml_find_all(temp_general_doc, ".//ss:Worksheet", temp_general_ns)
    temp_ep_wks <- xml_find_all(temp_ep_doc, ".//ss:Worksheet", temp_ep_ns)
    temp_paidExp_wks <- xml_find_all(temp_paidExp_doc, ".//ss:Worksheet", temp_paidExp_ns)
    #apply parsing algorithm and assign company indicator
    temp_org_df <- parse_generalInfo(temp_general_ns,temp_general_wks,seq_along(temp_general_wks)) %>% 
      merge(y=parse_earnedPrem(temp_ep_ns,temp_ep_wks,seq_along(temp_ep_wks)),by.x='Year',by.y='year') %>%
      merge(y=parse_paidExpenses(temp_paidExp_ns,temp_paidExp_wks,seq_along(temp_paidExp_wks)),by.x='Year',by.y='year') %>%
      add_column(Company=input.df[org,'name'],.before=2,.name_repair = 'minimal')
    #add company information to output data frame
    orgs_df <- rbind(orgs_df,temp_org_df)}
  #include target variable
  org_stockPrice <- parse_stockPrice(input.df)
  orgs_df <- merge(x=orgs_df,y=org_stockPrice,by=c('Year','Company'),all.x=TRUE)
  # include economic indicators
  econ_indicators <- xd.fred(input.indicators,'1996-01-01','2024-12-31') %>%
    fill('GDPC1',.direction='updown') %>%
    fill('CPALTT01USM657N',.direction='down') %>%
    mutate(Year = lubridate::year(observation_date)) %>%
    group_by(Year) %>%
    summarize(across(where(is.numeric), ~ tail(na.omit(.), 1))) %>%
    mutate(Year = as.character(Year))
  orgs_df <- merge(x=orgs_df,y=econ_indicators,by='Year',all.x=TRUE)
  #return output data frame
  orgs_df <- orgs_df %>%
    mutate_all(~if_else(. == 'NA', NA, .)) %>%
    select(-contains('na'))
  return(orgs_df)
}
```

```{r initialize parameters}
#reference: https://www.reinsurancene.ws/top-100-u-s-property-casualty-insurance-companies/
# sample_list <- c('State Farm','Berkshire Hathaway','Progressive','Allstate','Liberty Mutual',
#                  'Travelers','USAA','Chubb','Nationwide','Farmers Alliance',
#                  'American Family Ins','AIG','Fairfax Financial','Auto-Owners Ins','Tokio Marine',
#                  'Erie Ins','Berkley Ins','Hartford Fire Ins','Everest Re','CNA')

#define company names
pc_names <- c('Berkshire Hathaway A','Berkshire Hathaway B','Progressive','Allstate','Hanover Ins. Group',
              'Travelers','Zurich Ins. Group','Chubb','Fairfax Financial','Selective Ins. Group',
              'Allianz SE','AIG','Kemper Corp.','QBE Ins. Group','Tokio Marine',
              'Assurant Inc.','Berkley Ins.','Hartford Fire Ins.','Everest Re.','CNA')

#define company tickers...based on yahoo finance
pc_tickers <- c('brk-a','brk-b','prg','all','thg',
                'trv','zurn.sw','cb','ffh.to','sigi',
                'alv.de','aig','kmpr','qbe.ax','8766.t',
                'aiz','wrb','hig','eg','cna')

#define company local currency
pc_currency <- c('USD','USD','USD','USD','USD',
                 'USD','CHF','USD','CAD','USD',
                 'EUR','USD','USD','AUD','JPY',
                 'USD','USD','USD','USD','USD')

#initialize input data frame for data import
pcInput_df <- data.frame(name=pc_names,
                         ticker=pc_tickers,
                         currency=pc_currency) 

#real GDP, employment no, CPI, retail sales, money supply
pc_econIndicators <- c('GDPC1','PAYEMS','CPALTT01USM657N','MRTSSM44000USS','M2REAL')
```

```{r define base data}
#compile data...
  #1. financial statements
  #2. economic indicators
  #3. stock price
base_df <- data_import(pcInput_df,pc_econIndicators)
```

```{r define columns from literature review,rows.print=50}
eda_df <- base_df %>%
  mutate(across(c(net_income,policyholders_surplus,total_assets,total_liabilities,net_cash_from_operations,
                  unearned_prem,earned_prem,net_investment_gain,prem_deferred,prem_incourse,total_net_prem,
                  losses,lae,net_underwriting_gain,`change_in-surplus_policyholders`,
                  `1yr_loss_development`),
                ~suppressWarnings(as.numeric(.x))),
         return_on_surplus=net_income/policyholders_surplus,
         return_on_assets=net_income/total_assets,
         liab_to_liquidAssets=(total_liabilities-prem_deferred)/(net_cash_from_operations+ #cash
                                                     earned_prem+ #cash
                                                     unearned_prem+ #accounts receivable
                                                     net_investment_gain), #cash
         inCoursePrem_to_surplus=prem_incourse/policyholders_surplus,
         writtenPrem_to_surplus=total_net_prem/policyholders_surplus,
         lossReserves_to_surplus=(losses+lae)/policyholders_surplus,
         debt_to_equity=total_liabilities/policyholders_surplus,
         loss_ratio=(losses+lae)/earned_prem,
         combined_ratio=(losses+lae+underwriting_exp)/earned_prem,
         operating_ratio=(losses+lae+total_exp-net_investment_gain)/earned_prem,
         uw_margin=net_underwriting_gain/total_net_prem,
         investment_income=net_investment_gain/earned_prem,
         investment_yield=net_investment_gain/net_cash_from_operations,
         return_on_investments=net_investment_gain/policyholders_surplus,
         surplus_growth=`change_in-surplus_policyholders`/(policyholders_surplus-`change_in-surplus_policyholders`),
         assets_to_surplus=total_assets/policyholders_surplus,
         oneYRDev_to_surplus=`1yr_loss_development`/policyholders_surplus,
         Company=as.factor(Company),Year=as.factor(Year)) %>% 
  select(Year,Company,return_on_surplus,return_on_assets,liab_to_liquidAssets,inCoursePrem_to_surplus,
         writtenPrem_to_surplus,lossReserves_to_surplus,debt_to_equity,loss_ratio,uw_margin,investment_income,
         investment_yield,return_on_investments,stock_price,surplus_growth,oneYRDev_to_surplus,
         GDPC1,PAYEMS,CPALTT01USM657N,MRTSSM44000USS,M2REAL,combined_ratio,operating_ratio) %>%
  na.omit()
```

```{r loss ratio ts by company,rows.print=20,fig.width=20}
eda_df %>%
  mutate(date=as.Date(paste0(Year,'/12/31'))) %>%
  ggplot(aes(x=lossReserves_to_surplus,y=loss_ratio)) +
  geom_line() + 
  theme_minimal() +
  facet_wrap(~as.factor(Company)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) 
```

```{r}
eda_df %>% summary()
```

```{r multi-collinearity analysis}
#create correlation threshold
threshold <- 0.7
#create correlation matrix
ref_cor <- data.frame(cor(eda_df[,names(eda_df)[sapply(eda_df,is.numeric)]]))
#analyze correlation matrix...filter by threshold value
cor_data <- data.frame(names = names(ref_cor)) #create a new table for filtered values
for (col in names(ref_cor)) { #evaluate each column in the correlation matrix
  cor_vec <- ref_cor[, col] #collect individual column correlation scores
  cor_data <- cor_data %>%
    mutate(!!col := case_when( #conditional definition...based on threshold value
                      abs(cor_vec) >= threshold ~ cor_vec, #when value meets threshold
                      abs(cor_vec) < threshold ~ NA, #when value violates threshold
                    ))}
#display filtered correlation matrix
cor_data  
#correlated combinations
  #return_on_assets->return_on_surplus
  #liab_to_liquidAssets->loss_ratio->operating_ratio->combined_ratio
  #lossReserves_to_surplus->debt_to_equity
  #GDPC1->PAYEMS->MRTSSM44000USS->M2REAL
```

```{r lm setup}
#set split seed
set.seed(100)
#define correlated columns
correlated_cols <- c('operating_ratio','combined_ratio','liab_to_liquidAssets','debt_to_equity','M2REAL',
                     'PAYEMS','MRTSSM44000USS','return_on_assets','GDPC1','CPALTT01USM657N','Company')
#define split criteria
lm_trainIndices <- createDataPartition(eda_df$loss_ratio, p = 0.75, list = FALSE)
#perform split operation...train & test samples
lm_train <- eda_df[lm_trainIndices, names(eda_df) %notin% correlated_cols]
lm_test  <- eda_df[-lm_trainIndices, names(eda_df) %notin% correlated_cols]
#separate samples into predictors (x) & target (y)
lm_XTrain <- train %>% dplyr::select(-c(loss_ratio)); lm_YTrain <- train$loss_ratio
lm_XTest <- test %>% dplyr::select(-c(loss_ratio)); lm_YTest <- test$loss_ratio
```

```{r lm model fit}
#set modeling seed
set.seed(100)
#fit model object...with all columns
mlr.model <- lm(loss_ratio~.,data=lm_train)
#perform predictions with fitted model...using test sample
mlr.pred <- predict(mlr.model,newdata=lm_XTest)
#compute rmse & r-squared metrics...using test sample
print(paste0('Test MLR RMSE: ',round(as.numeric(ModelMetrics::rmse(actual=lm_YTest,pred=mlr.pred)),3)))
print(paste0('Test MLR R-Squared: ',round(as.numeric(rsq(data.frame(actual=lm_YTest,pred=mlr.pred),truth=actual,estimate=pred)[1,'.estimate']),2)*100,'%'))
```
```{r lm diagnostics}
#homoscedasticity check
variance.plot <- function(model){ #plot fitted values vs residuals 
  #save the residuals from the model
  residuals <- residuals(model)
  #create the variance plot
  plot(fitted(model), residuals, xlab = 'fitted values', ylab = 'residuals', 
       main = 'variance plot for homoscedasticity')
  
  # Add a smooth line to the plot
  lines(lowess(fitted(model), residuals), col = 'red')
}
#display variance plot
variance.plot(mlr.model)
#display q-q plots
qqnorm(residuals(mlr.model),
       main='normal q-q plot',
       xlab='theoretical quantiles',
       ylab='sample quantiles')
qqline(residuals(mlr.model))
#display cook's distance metrics
plot(mlr.model,4,main=paste0("cook's distance with cutoff of ~",round(mean(cooks.distance(mlr.model))*3,3)))
#display vif metrics
vif(mlr.model) %>%
  as.data.frame() %>%
  mutate(feature=rownames(vif(mlr.model))) %>%
  ggplot() +
  geom_col(aes(y=feature,x=GVIF)) +
  labs(title='variance inflation factors',
       subtitle='using gvif',
       x='gvif',
       y='feature')+
  theme_minimal()+
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) 
```